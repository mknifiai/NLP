{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d95ac4-766c-4e7e-9879-596222a3500c",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b02c7a-868d-442a-8ae4-094927d75585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "110adb5e-89ba-4d8d-840d-d732098c1492",
   "metadata": {},
   "source": [
    "#### Formalizing classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e189eb-979a-47b0-b27b-7354e1f201e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"fclf.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"fclf.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958dfc6-5613-42c3-8972-07b94c66955f",
   "metadata": {},
   "source": [
    "#### The Na√Øve Bayes‚Äô Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1ac3ae-8524-4713-b4e9-3c18a0e1c788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"bclf.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"bclf.png\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce8064-c57f-4db5-b310-cb2849600f02",
   "metadata": {},
   "source": [
    "##### Bayes‚Äô rule. \n",
    "- It relates the posterior probability $P(C_{i}|X_{j})$ with the prior probability $P (C_{i})$ and class-conditional probability $P (X_{j} |C_{i})$. \n",
    "- The denominator acts to normalise everything, so that all the probabilities sum to 1\n",
    "- When $X$ is a vector of feature values instead of just one feature. This is known as ***the maximum a posteriori or MAP hypothesis***, and it gives us a way to choose which class to choose as the output one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25a8e0-c335-4278-aa2e-1176febf8afd",
   "metadata": {},
   "source": [
    "Naive: The features are independent of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3184632b-70f9-461f-9958-5b6a60425880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"nb.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"nb.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69079809-ce3a-4565-9de4-b288ddcc21dd",
   "metadata": {},
   "source": [
    "So the classifier rule for the na√Øve Bayes‚Äô classifier is to select the class $C_{i}$ for which the following computation is the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d76d68-caf6-4afc-ac80-c2f5e43a873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"nbclf.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"nbclf.png\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcc5c9-e194-4290-85bd-1bd3d8c8cd73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a0679-c48b-4a49-b567-bd8b90bc7b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfc8dba-a072-45bb-890f-de5b82852d81",
   "metadata": {},
   "source": [
    "#### Perception Test Algorithm for Binary Classification:\n",
    "#### Predict class -1 or +1 for example x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb3b938-cfea-442a-b7b8-d8ae5ca4a2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"teclf.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"teclf.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8eb81-b90c-4ac4-9e16-5753b5ba9a70",
   "metadata": {},
   "source": [
    "#### Perceptron Training Algorithm:\n",
    "#### Find good values for (w,b) given training data D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726435bf-947b-48ad-8eeb-aa1051c7c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"trclf.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"trclf.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4ec50-9cc8-4d56-be34-040fdc6a4d1e",
   "metadata": {},
   "source": [
    "#### Machine Learning Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce149c6e-18bc-4dd7-9ecb-09f0a2a36711",
   "metadata": {},
   "source": [
    "##### $x$ is often called the feature vector\n",
    "- its elements are defined (by us, the model designers) to capture properties or features of the input that are expected to correlate with predictions\n",
    "##### $w$ and $b$ are the parameters of the classifier\n",
    "- they are needed to fully define the classification function $f(x) = y$\n",
    "- their values are found by the training algorithm using training data D\n",
    "##### MaxIter is a hyperparameter\n",
    "- controls when training stops\n",
    "- MaxIter impacts the nature of function $f$ indirectly\n",
    "\n",
    "All of the above affect the performance of the final classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee246aaa-70d3-40ea-bc79-2f7843a0ae07",
   "metadata": {},
   "source": [
    "#### Perceptron for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78db7115-e95f-4a99-b7bd-6e7ade5df596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"pclf.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"pclf.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bef23-6b81-4aac-b8c7-8d474f306a8f",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d871a71c-99ce-4b24-a478-7e562a932686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"msvm.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"msvm.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ba0acd-b19e-4c12-a5e6-5d7f1bd03877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"esvm.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"esvm.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4565c20-33e6-4298-af03-d0845dd7793a",
   "metadata": {},
   "source": [
    "#### More Machine Learning vocabulary:\n",
    "#### overfitting/underfitting/generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b8a9c-1d3a-4271-ab33-73ca80f1eaeb",
   "metadata": {},
   "source": [
    "##### Training error is not sufficient\n",
    "- We care about generalization to new examples\n",
    "- A classifier can classify training data perfectly, yet classify new examples incorrectly\n",
    "     - Because training examples are only a sample of data distribution\n",
    "        - a feature might correlate with class by coincidence\n",
    "     - Because training examples could be noisy \n",
    "         - e.g., accident in labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990a32b-6e6e-465f-96e6-73e595696ddb",
   "metadata": {},
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9d34c-6483-4a67-a857-7e2618cf294e",
   "metadata": {},
   "source": [
    "Consider a model ùúÉ and its:\n",
    "   - Error rate over training data $error_{train}(ùúÉ)$\n",
    "   - True error rate over all data $error_{true} ùúÉ$\n",
    "\n",
    "We say ‚Ñé overfits the training data if\n",
    "   - $error_{train} (ùúÉ) < error_{true} (ùúÉ)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0db889-6ca9-4a82-b092-f0652155f42f",
   "metadata": {},
   "source": [
    "#### Evaluating on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d4144-a5dd-480f-9d3c-eebb5f3db049",
   "metadata": {},
   "source": [
    "Problem: we don‚Äôt know $error_{true} ùúÉ$ ! \n",
    "\n",
    "- Solution:\n",
    "    - we set aside a test set\n",
    "         - some examples that will be used for evaluation\n",
    "    - we don‚Äôt look at them during training!\n",
    "    - after learning a classifier ùúÉ, we calculate $error_{test}(ùúÉ)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393e1c5-7eec-454c-a3b0-b4531bf28ceb",
   "metadata": {},
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f566ac-28e4-4ffa-8348-f9e1e46aeae9",
   "metadata": {},
   "source": [
    "- Another way of putting it\n",
    "- A classifier ùúÉ is said to overfit the training data, if there are other parameters ùúÉ‚Ä≤, such that\n",
    "    - ùúÉ has a smaller error than ùúÉ‚Ä≤ on the training data\n",
    "    - but ùúÉ has larger error on the test data than ùúÉ‚Ä≤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87e9c0-3f73-4a5a-8764-da8a573d6305",
   "metadata": {},
   "source": [
    "#### Underfitting/Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618085d-1946-438d-9222-5897e7d8fa8d",
   "metadata": {},
   "source": [
    "- Underfitting\n",
    "    - Learning algorithm had the opportunity to learn more from training data, but didn‚Äôt \n",
    "\n",
    "- Overfitting\n",
    "    - Learning algorithm paid too much attention to idiosyncracies of the training data; the resulting classifier doesn‚Äôt generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4883b19-3974-4925-8f1f-4f3e9beb5c12",
   "metadata": {},
   "source": [
    "#### Back to the Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f065d-59e9-4238-b811-356f4b59fc89",
   "metadata": {},
   "source": [
    "- Practical strategies to improve generalization for the perceptron\n",
    "    - Averaging\n",
    "    - Randomize order of training data\n",
    "    - Use a development test set to find good hyperparameter values\n",
    "        - E.g., early stopping is a good strategy to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb264a41-c5ab-497c-ab87-f1cada959130",
   "metadata": {},
   "source": [
    "#### Logistic Regression for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b5741e-4e14-4349-8cae-15ba34aa13bd",
   "metadata": {},
   "source": [
    "#### From Perceptron to Probabilities:\n",
    "#### the Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1415b65-afae-42fb-b3f9-54641218d442",
   "metadata": {},
   "source": [
    "- The perceptron gives us a prediction y, and the activation can take any real value\n",
    "- What if we want a probability p(y|x) instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341f81c-bd51-4f17-bf71-ccd2cdee050c",
   "metadata": {},
   "source": [
    "#### The sigmoid function (aka the logistic function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d0a70a-d633-4a42-af02-ce73c4106801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"lr.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"lr.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007b9cef-b476-4c80-b005-3abfd979da07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"lre.png\" width=\"300\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"lre.png\", width=300, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef48340-578e-4fd9-b207-9fc85039d08e",
   "metadata": {},
   "source": [
    "#### Making Predictions with the Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aed2b6-e8f9-4009-9514-5132dd62056b",
   "metadata": {},
   "source": [
    "Given a test instance x, predict class 1 if P(y=1|x) > 0.5, and 0\n",
    "otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "248df143-186c-4060-8650-9a3b4ef6b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"lrd.png\" width=\"300\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"lrd.png\", width=300, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ada7e-4bf6-41ed-9dd6-9cbf49dd6f8c",
   "metadata": {},
   "source": [
    "Inputs x for which P(y=1|x) = 0.5 constitute the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62715d-eb36-4e4c-9c11-051fef2e033b",
   "metadata": {},
   "source": [
    "#### Ingredients required for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74cab8-95bb-48f4-b840-088552ab49b5",
   "metadata": {},
   "source": [
    "- Loss function or cost function\n",
    "    - A measure of distance between classifier prediction and true label for a given set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4436e4-c2f2-4f84-a6c6-3d7e3fdd95b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"loss.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"loss.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295da6f-9697-479a-946a-44ffd570060a",
   "metadata": {},
   "source": [
    "- An algorithm to minimize this loss\n",
    "    - Here we‚Äôll introduce stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a07d81-2e92-4293-af4a-3f5eefad2e59",
   "metadata": {},
   "source": [
    "#### The cross-entropy loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895682d4-103b-49ac-822a-4584bca2d3ec",
   "metadata": {},
   "source": [
    "- Loss function used for logistic regression and often for neural networks\n",
    "- Defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f27c0a0f-ea59-4f79-80fd-34146f21631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"ce.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"ce.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd72fba-8d78-44bb-bdd6-7aa1a35cc284",
   "metadata": {},
   "source": [
    "#### Deriving the cross-entropy loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0298634-a3db-4e3f-9fd2-b3c9d96c9cb0",
   "metadata": {},
   "source": [
    "- Conditional maximum likelihood\n",
    "    - Choose parameters that maximize the log probability of true labels y given inputs x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e82ca1c-39ff-4b2a-8203-142b6558764c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"cm.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"cm.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35289718-ad43-414d-a6f3-46622e43c4a3",
   "metadata": {},
   "source": [
    "- Cross-entropy loss is defined as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4f2389-ce93-4682-b275-0a24a4acb103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"dce.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"dce.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f0379-fb33-4404-a905-59ed6815b7ee",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ab24c5-0882-40fa-8d6d-bf446f551ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"gd.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"gd.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ee258-cfd2-4ed9-9922-d56836c454be",
   "metadata": {},
   "source": [
    "#### Illustrating GradientDescent\n",
    "- The gradient indicates the direction of greatest increase of the cost/loss function.\n",
    "\n",
    "- Gradient descent finds parameters (w,b) that decrease the loss by taking a step in the opposite direction of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214737ac-533b-459b-920d-8d4b3b13c401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"igd.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"igd.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0295141c-6288-495e-a1b6-b68c25bb4438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"cgd.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"cgd.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7083d056-04c4-4cb2-a6aa-f9f717a8c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"dces.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"dces.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a06182-fa1e-4077-b369-8af84e57f742",
   "metadata": {},
   "source": [
    "### SGD hyperparameter: the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0d7f7-ffa7-4eea-96c5-d6604dd3233e",
   "metadata": {},
   "source": [
    "- The hyperparameter ùúÇ that control the size of the step down the gradient is called the learning rate\n",
    "\n",
    "- If ùúÇ is too large, training might not converge; if ùúÇ is too small, training might be very slow.\n",
    "\n",
    "- How to set the learning rate? Common strategies:\n",
    "    - decay over time: $ùúÇ =1/(ùê∂+n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cba99-dc8a-4bff-a6a2-e93782ef07c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ead776c6-9d67-425d-bfb5-6dbd6c7c9178",
   "metadata": {},
   "source": [
    "### A multiclass logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc0141-c07e-4129-abee-a2a0946aa79e",
   "metadata": {},
   "source": [
    "***Goal***: predict probability P(y=c|x), where c is one of k classes in set C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4ee80-e36c-4b60-ad0a-e8f88724349d",
   "metadata": {},
   "source": [
    "#### The softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37183f4-994a-42ff-9b3a-1987b9a053e9",
   "metadata": {},
   "source": [
    "- A generalization of the sigmoid\n",
    "- Input: a vector z of dimensionality k\n",
    "    - $z = [z_{1},z_{2},\\cdots,z_{k}]$\n",
    "- Output: a vector of dimensionality k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "559926ce-52b9-4789-a1be-27a4b8e94d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"softmax.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"softmax.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe59235-c3a4-48fd-80a1-06b6e0865d25",
   "metadata": {},
   "source": [
    "#### Model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f2ae227-c10d-4a6d-a479-587865fd638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"softmaxmd.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"softmaxmd.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38864089-d6b9-4402-82a1-0dccf3a4374d",
   "metadata": {},
   "source": [
    "#### Learning in Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dae7eb-df6e-4d6d-bf48-c41cc758a080",
   "metadata": {},
   "source": [
    "- Loss function for a single example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3491dc3b-de0d-4c6f-93f2-6d01345de966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"lmc.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"lmc.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d461af4-dc0b-4263-998a-5ffa216cd6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
